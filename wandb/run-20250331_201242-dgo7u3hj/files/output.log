/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Encoding: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.
Epoch 1/1 - Training:   0%|                                                              | 0/290402 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_train.py", line 571, in <module>
    main()
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_train.py", line 546, in main
    train(
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_train.py", line 358, in train
    loss = loss_func(
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_utils.py", line 76, in dwd_loss
    return alpha * nce_loss(whispa_embs, sbert_embs, tau) + \
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_utils.py", line 46, in nce_loss
    combined = torch.cat([z_a, z_b], dim=0)  # shape (2 * batch_size, emb_dims)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)
