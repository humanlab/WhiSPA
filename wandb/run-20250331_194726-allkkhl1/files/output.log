/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Encoding:   0%|                                                                                                                                           | 0/1 [00:00<?, ?it/s]
[' It depends.', ' But there is a lot.']
Epoch 1/1 - Training:   0%|                                                                                                                          | 0/290402 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_train.py", line 568, in <module>
    main()
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_train.py", line 543, in main
    train(
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_train.py", line 341, in train
    sbert_embs = sbert.module.encode(batch['message'], task='classification', truncate_dims=config.hidden_size)
  File "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/cronus_data/rrao/.hf_home/modules/transformers_modules/jinaai/xlm-roberta-flash-implementation/2b6bc3f30750b3a9648fe9b63448c09920efe9be/modeling_lora.py", line 423, in encode
    return self.roberta.encode(
  File "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/cronus_data/rrao/.hf_home/modules/transformers_modules/jinaai/xlm-roberta-flash-implementation/2b6bc3f30750b3a9648fe9b63448c09920efe9be/modeling_xlm_roberta.py", line 584, in encode
    encoded_input = self.tokenizer(
  File "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2887, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2975, in _call_one
    return self.batch_encode_plus(
  File "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3177, in batch_encode_plus
    return self._batch_encode_plus(
TypeError: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate_dims'
