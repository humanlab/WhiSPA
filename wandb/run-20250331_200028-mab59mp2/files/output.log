/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Encoding:   0%|                                                                                                                                           | 0/1 [00:01<?, ?it/s]
Epoch 1/1 - Training:   0%|                                                                                                                          | 0/290402 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_train.py", line 575, in <module>
    main()
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_train.py", line 550, in main
    train(
  File "/home/rrao/workspace/WhiSPA/pretrain/whispa_train.py", line 340, in train
    sbert_embs = torch.tensor(sbert.module.encode(
  File "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/cronus_data/rrao/.hf_home/modules/transformers_modules/jinaai/xlm-roberta-flash-implementation/2b6bc3f30750b3a9648fe9b63448c09920efe9be/modeling_lora.py", line 423, in encode
    return self.roberta.encode(
  File "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/cronus_data/rrao/.hf_home/modules/transformers_modules/jinaai/xlm-roberta-flash-implementation/2b6bc3f30750b3a9648fe9b63448c09920efe9be/modeling_xlm_roberta.py", line 594, in encode
    token_embs = self.forward(**encoded_input, **lora_arguments)[0]
  File "/cronus_data/rrao/.hf_home/modules/transformers_modules/jinaai/xlm-roberta-flash-implementation/2b6bc3f30750b3a9648fe9b63448c09920efe9be/modeling_xlm_roberta.py", line 707, in forward
    hidden_states = self.embeddings(
  File "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/cronus_data/rrao/.hf_home/modules/transformers_modules/jinaai/xlm-roberta-flash-implementation/2b6bc3f30750b3a9648fe9b63448c09920efe9be/embedding.py", line 66, in forward
    embeddings[task_indices] = task_embeddings
RuntimeError: Index put requires the source and destination dtypes match, got BFloat16 for the destination and Float for the source.
